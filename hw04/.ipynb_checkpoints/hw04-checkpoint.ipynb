{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620, Assignment 1: “hello, graph world”\n",
    "\n",
    "### Group 1 Members:\n",
    "\n",
    "* Mauricio Alarcon\n",
    "* Sekhar Mekala \n",
    "* Aadi Kalloo\n",
    "* Srinivasa Illapani\n",
    "* Param Singh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "In this assignment, you’re asked to create the nodes and edges for a basic graph, such as the Krackhardt kite shown\n",
    "below. (You’re welcome to substitute data of your own choosing).\n",
    "\n",
    "![](https://raw.githubusercontent.com/rmalarc/DATA620/master/hw01/kite.png)\n",
    "\n",
    "\n",
    "# Assignment Response\n",
    "\n",
    "Here we did:\n",
    "\n",
    "* Use Turi/Graphlab API to load data into SFrames\n",
    "* create a Graph data structure from these frames\n",
    "* Use general graphlab methods to explore the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import plotly\n",
    "#gl.canvas.set_target('ipynb') # use IPython Notebook output for GraphLab Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Creating Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'austen-emma.txt',\n",
       " u'austen-persuasion.txt',\n",
       " u'austen-sense.txt',\n",
       " u'bible-kjv.txt',\n",
       " u'blake-poems.txt',\n",
       " u'bryant-stories.txt',\n",
       " u'burgess-busterbrown.txt',\n",
       " u'carroll-alice.txt',\n",
       " u'chesterton-ball.txt',\n",
       " u'chesterton-brown.txt',\n",
       " u'chesterton-thursday.txt',\n",
       " u'edgeworth-parents.txt',\n",
       " u'melville-moby_dick.txt',\n",
       " u'milton-paradise.txt',\n",
       " u'shakespeare-caesar.txt',\n",
       " u'shakespeare-hamlet.txt',\n",
       " u'shakespeare-macbeth.txt',\n",
       " u'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus is 260819 words\n"
     ]
    }
   ],
   "source": [
    "moby_dick = nltk.corpus.gutenberg.words('melville-moby_dick.txt')\n",
    "print('Length of corpus is %d words') % len(moby_dick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "filtered_w_stopwords = [word.lower() for word in moby_dick if re.search(\"\\w\", word)]\n",
    "filtered_wo_stopwords = [e.lower() for e in filtered_w_stopwords if not e.lower() in stopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218621"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_w_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110719"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_wo_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17140 unique words when stopwords are included in text\n",
      "There are 16994 unique words when stopwords are excluded from text\n"
     ]
    }
   ],
   "source": [
    "fdist_w_stopwords = nltk.FreqDist(filtered_w_stopwords)\n",
    "fdist_wo_stopwords = nltk.FreqDist(filtered_wo_stopwords)\n",
    "print('There are %d unique words when stopwords are included in text') % len(fdist_w_stopwords)\n",
    "print('There are %d unique words when stopwords are excluded from text') % len(fdist_wo_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words that make up half total words in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words that represent half of the total words in the corpus when stopwords are included in the text is 90\n"
     ]
    }
   ],
   "source": [
    "worddf_w_stopwords = pd.DataFrame(fdist_w_stopwords.most_common(len(fdist_w_stopwords)))\n",
    "half_total_w_stopwords = len(filtered_w_stopwords)/2\n",
    "counter = 0\n",
    "num_words_w_stopwords = 0\n",
    "for i in range(0, len(worddf_w_stopwords[1])):\n",
    "    counter = counter + worddf_w_stopwords[1][i]\n",
    "    if counter >= half_total_w_stopwords:\n",
    "        num_words_w_stopwords = i\n",
    "        break\n",
    "print('The number of unique words that represent half of the total words in the corpus when stopwords are included in the text is %d') % num_words_w_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words that represent half of the total words in the corpus when stopwords are excluded from the text is 691\n"
     ]
    }
   ],
   "source": [
    "worddf_wo_stopwords = pd.DataFrame(fdist_wo_stopwords.most_common(len(fdist_wo_stopwords)))\n",
    "half_total_wo_stopwords = len(filtered_wo_stopwords)/2\n",
    "counter = 0\n",
    "num_words_wo_stopwords = 0\n",
    "for i in range(0, len(worddf_wo_stopwords[1])):\n",
    "    counter = counter + worddf_wo_stopwords[1][i]\n",
    "    if counter >= half_total_wo_stopwords:\n",
    "        num_words_wo_stopwords = i\n",
    "        break\n",
    "print('The number of unique words that represent half of the total words in the corpus when stopwords are excluded from the text is %d') % num_words_wo_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55313"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200 Highest Frequency Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'the', 14431),\n",
       " (u'of', 6609),\n",
       " (u'and', 6430),\n",
       " (u'a', 4736),\n",
       " (u'to', 4625),\n",
       " (u'in', 4172),\n",
       " (u'that', 3085),\n",
       " (u'his', 2530),\n",
       " (u'it', 2522),\n",
       " (u'i', 2127),\n",
       " (u'he', 1896),\n",
       " (u'but', 1818),\n",
       " (u's', 1802),\n",
       " (u'as', 1741),\n",
       " (u'is', 1725),\n",
       " (u'with', 1722),\n",
       " (u'was', 1644),\n",
       " (u'for', 1617),\n",
       " (u'all', 1526),\n",
       " (u'this', 1394),\n",
       " (u'at', 1319),\n",
       " (u'whale', 1226),\n",
       " (u'by', 1204),\n",
       " (u'not', 1151),\n",
       " (u'from', 1088),\n",
       " (u'him', 1067),\n",
       " (u'so', 1065),\n",
       " (u'on', 1062),\n",
       " (u'be', 1045),\n",
       " (u'one', 921),\n",
       " (u'you', 894),\n",
       " (u'there', 869),\n",
       " (u'now', 785),\n",
       " (u'had', 779),\n",
       " (u'have', 768),\n",
       " (u'or', 713),\n",
       " (u'were', 684),\n",
       " (u'they', 667),\n",
       " (u'which', 648),\n",
       " (u'like', 647),\n",
       " (u'me', 633),\n",
       " (u'then', 630),\n",
       " (u'their', 620),\n",
       " (u'some', 618),\n",
       " (u'what', 618),\n",
       " (u'when', 606),\n",
       " (u'are', 598),\n",
       " (u'an', 596),\n",
       " (u'my', 589),\n",
       " (u'no', 586),\n",
       " (u'upon', 566),\n",
       " (u'out', 538),\n",
       " (u'man', 527),\n",
       " (u'into', 523),\n",
       " (u'up', 521),\n",
       " (u'ship', 518),\n",
       " (u'ahab', 511),\n",
       " (u'more', 508),\n",
       " (u'if', 481),\n",
       " (u'them', 474),\n",
       " (u'ye', 472),\n",
       " (u'we', 460),\n",
       " (u'sea', 455),\n",
       " (u'old', 450),\n",
       " (u'would', 432),\n",
       " (u'other', 416),\n",
       " (u'been', 415),\n",
       " (u'over', 409),\n",
       " (u'these', 403),\n",
       " (u'will', 391),\n",
       " (u'though', 384),\n",
       " (u'down', 378),\n",
       " (u'its', 376),\n",
       " (u'only', 376),\n",
       " (u'such', 370),\n",
       " (u'who', 363),\n",
       " (u'yet', 345),\n",
       " (u'head', 345),\n",
       " (u'boat', 336),\n",
       " (u'time', 334),\n",
       " (u'long', 333),\n",
       " (u'her', 332),\n",
       " (u'captain', 329),\n",
       " (u'any', 327),\n",
       " (u'here', 325),\n",
       " (u'very', 322),\n",
       " (u'still', 312),\n",
       " (u'about', 310),\n",
       " (u'than', 309),\n",
       " (u'do', 307),\n",
       " (u'great', 306),\n",
       " (u'those', 306),\n",
       " (u'said', 304),\n",
       " (u'before', 299),\n",
       " (u'two', 298),\n",
       " (u'has', 292),\n",
       " (u't', 291),\n",
       " (u'seemed', 283),\n",
       " (u'must', 283),\n",
       " (u'most', 282),\n",
       " (u'white', 281),\n",
       " (u'last', 277),\n",
       " (u'see', 272),\n",
       " (u'thou', 271),\n",
       " (u'way', 271),\n",
       " (u'after', 270),\n",
       " (u'whales', 268),\n",
       " (u'again', 263),\n",
       " (u'did', 258),\n",
       " (u'stubb', 257),\n",
       " (u'how', 255),\n",
       " (u'queequeg', 252),\n",
       " (u'your', 249),\n",
       " (u'little', 249),\n",
       " (u'round', 247),\n",
       " (u'while', 246),\n",
       " (u'three', 245),\n",
       " (u'sperm', 244),\n",
       " (u'men', 244),\n",
       " (u'say', 244),\n",
       " (u'may', 240),\n",
       " (u'can', 236),\n",
       " (u'first', 235),\n",
       " (u'through', 233),\n",
       " (u'every', 232),\n",
       " (u'well', 230),\n",
       " (u'us', 228),\n",
       " (u'being', 225),\n",
       " (u'much', 223),\n",
       " (u'where', 220),\n",
       " (u'off', 220),\n",
       " (u'could', 216),\n",
       " (u'good', 216),\n",
       " (u'hand', 214),\n",
       " (u'same', 214),\n",
       " (u'side', 208),\n",
       " (u'our', 207),\n",
       " (u'never', 206),\n",
       " (u'ever', 206),\n",
       " (u'look', 205),\n",
       " (u'himself', 205),\n",
       " (u'own', 205),\n",
       " (u'starbuck', 198),\n",
       " (u'deck', 196),\n",
       " (u'almost', 195),\n",
       " (u'go', 194),\n",
       " (u'even', 191),\n",
       " (u'water', 190),\n",
       " (u'thing', 188),\n",
       " (u'too', 185),\n",
       " (u'should', 183),\n",
       " (u'away', 183),\n",
       " (u'might', 183),\n",
       " (u'come', 179),\n",
       " (u'made', 178),\n",
       " (u'world', 176),\n",
       " (u'day', 176),\n",
       " (u'sir', 175),\n",
       " (u'life', 174),\n",
       " (u'pequod', 173),\n",
       " (u'chapter', 173),\n",
       " (u'fish', 169),\n",
       " (u'among', 167),\n",
       " (u'many', 166),\n",
       " (u'seen', 165),\n",
       " (u'far', 165),\n",
       " (u'back', 164),\n",
       " (u'let', 158),\n",
       " (u'line', 158),\n",
       " (u'nor', 156),\n",
       " (u'eyes', 156),\n",
       " (u'without', 156),\n",
       " (u'oh', 156),\n",
       " (u'aye', 155),\n",
       " (u'cried', 155),\n",
       " (u'sort', 152),\n",
       " (u'god', 152),\n",
       " (u'know', 152),\n",
       " (u'right', 151),\n",
       " (u'night', 150),\n",
       " (u'thought', 150),\n",
       " (u'part', 149),\n",
       " (u'once', 149),\n",
       " (u'boats', 147),\n",
       " (u'air', 143),\n",
       " (u'crew', 140),\n",
       " (u'don', 139),\n",
       " (u'take', 137),\n",
       " (u'whole', 137),\n",
       " (u'half', 136),\n",
       " (u'tell', 135),\n",
       " (u'against', 134),\n",
       " (u'thus', 133),\n",
       " (u'things', 132),\n",
       " (u'whaling', 131),\n",
       " (u'thee', 131),\n",
       " (u'came', 130),\n",
       " (u'soon', 130),\n",
       " (u'hands', 130),\n",
       " (u'mast', 129)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords included in text\n",
    "mostcommon_w_stopwords = fdist_w_stopwords.most_common(200)\n",
    "mostcommon_w_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'whale', 1226),\n",
       " (u'one', 921),\n",
       " (u'like', 647),\n",
       " (u'upon', 566),\n",
       " (u'man', 527),\n",
       " (u'ship', 518),\n",
       " (u'ahab', 511),\n",
       " (u'ye', 472),\n",
       " (u'sea', 455),\n",
       " (u'old', 450),\n",
       " (u'would', 432),\n",
       " (u'though', 384),\n",
       " (u'yet', 345),\n",
       " (u'head', 345),\n",
       " (u'boat', 336),\n",
       " (u'time', 334),\n",
       " (u'long', 333),\n",
       " (u'captain', 329),\n",
       " (u'still', 312),\n",
       " (u'great', 306),\n",
       " (u'said', 304),\n",
       " (u'two', 298),\n",
       " (u'seemed', 283),\n",
       " (u'must', 283),\n",
       " (u'white', 281),\n",
       " (u'last', 277),\n",
       " (u'see', 272),\n",
       " (u'thou', 271),\n",
       " (u'way', 271),\n",
       " (u'whales', 268),\n",
       " (u'stubb', 257),\n",
       " (u'queequeg', 252),\n",
       " (u'little', 249),\n",
       " (u'round', 247),\n",
       " (u'three', 245),\n",
       " (u'sperm', 244),\n",
       " (u'men', 244),\n",
       " (u'say', 244),\n",
       " (u'may', 240),\n",
       " (u'first', 235),\n",
       " (u'every', 232),\n",
       " (u'well', 230),\n",
       " (u'us', 228),\n",
       " (u'much', 223),\n",
       " (u'could', 216),\n",
       " (u'good', 216),\n",
       " (u'hand', 214),\n",
       " (u'side', 208),\n",
       " (u'never', 206),\n",
       " (u'ever', 206),\n",
       " (u'look', 205),\n",
       " (u'starbuck', 198),\n",
       " (u'deck', 196),\n",
       " (u'almost', 195),\n",
       " (u'go', 194),\n",
       " (u'even', 191),\n",
       " (u'water', 190),\n",
       " (u'thing', 188),\n",
       " (u'away', 183),\n",
       " (u'might', 183),\n",
       " (u'come', 179),\n",
       " (u'made', 178),\n",
       " (u'world', 176),\n",
       " (u'day', 176),\n",
       " (u'sir', 175),\n",
       " (u'life', 174),\n",
       " (u'pequod', 173),\n",
       " (u'chapter', 173),\n",
       " (u'fish', 169),\n",
       " (u'among', 167),\n",
       " (u'many', 166),\n",
       " (u'seen', 165),\n",
       " (u'far', 165),\n",
       " (u'back', 164),\n",
       " (u'let', 158),\n",
       " (u'line', 158),\n",
       " (u'eyes', 156),\n",
       " (u'without', 156),\n",
       " (u'oh', 156),\n",
       " (u'aye', 155),\n",
       " (u'cried', 155),\n",
       " (u'sort', 152),\n",
       " (u'god', 152),\n",
       " (u'know', 152),\n",
       " (u'right', 151),\n",
       " (u'night', 150),\n",
       " (u'thought', 150),\n",
       " (u'part', 149),\n",
       " (u'boats', 147),\n",
       " (u'air', 143),\n",
       " (u'crew', 140),\n",
       " (u'take', 137),\n",
       " (u'whole', 137),\n",
       " (u'half', 136),\n",
       " (u'tell', 135),\n",
       " (u'thus', 133),\n",
       " (u'things', 132),\n",
       " (u'whaling', 131),\n",
       " (u'thee', 131),\n",
       " (u'came', 130),\n",
       " (u'soon', 130),\n",
       " (u'hands', 130),\n",
       " (u'mast', 129),\n",
       " (u'small', 128),\n",
       " (u'feet', 127),\n",
       " (u'full', 123),\n",
       " (u'something', 123),\n",
       " (u'till', 122),\n",
       " (u'think', 122),\n",
       " (u'saw', 116),\n",
       " (u'place', 116),\n",
       " (u'called', 116),\n",
       " (u'found', 115),\n",
       " (u'another', 115),\n",
       " (u'nothing', 115),\n",
       " (u'poor', 114),\n",
       " (u'towards', 114),\n",
       " (u'thy', 113),\n",
       " (u'times', 112),\n",
       " (u'make', 112),\n",
       " (u'along', 110),\n",
       " (u'heard', 110),\n",
       " (u'body', 110),\n",
       " (u'high', 108),\n",
       " (u'flask', 108),\n",
       " (u'stand', 107),\n",
       " (u'sight', 105),\n",
       " (u'moment', 105),\n",
       " (u'voyage', 103),\n",
       " (u'sail', 102),\n",
       " (u'sun', 102),\n",
       " (u'end', 100),\n",
       " (u'new', 99),\n",
       " (u'hold', 98),\n",
       " (u'strange', 98),\n",
       " (u'shall', 97),\n",
       " (u'went', 97),\n",
       " (u'years', 96),\n",
       " (u'nantucket', 96),\n",
       " (u'leviathan', 96),\n",
       " (u'face', 95),\n",
       " (u'get', 95),\n",
       " (u'however', 95),\n",
       " (u'dead', 92),\n",
       " (u'black', 92),\n",
       " (u'also', 91),\n",
       " (u'heart', 91),\n",
       " (u'whether', 91),\n",
       " (u'death', 90),\n",
       " (u'oil', 90),\n",
       " (u'stood', 90),\n",
       " (u'going', 89),\n",
       " (u'certain', 89),\n",
       " (u'leg', 89),\n",
       " (u'indeed', 89),\n",
       " (u'arm', 89),\n",
       " (u'perhaps', 89),\n",
       " (u'eye', 88),\n",
       " (u'sometimes', 87),\n",
       " (u'iron', 87),\n",
       " (u'true', 87),\n",
       " (u'whose', 87),\n",
       " (u'matter', 87),\n",
       " (u'seas', 87),\n",
       " (u'seems', 87),\n",
       " (u'ships', 87),\n",
       " (u'heads', 86),\n",
       " (u'give', 86),\n",
       " (u'seem', 85),\n",
       " (u'jonah', 85),\n",
       " (u'moby', 84),\n",
       " (u'dick', 84),\n",
       " (u'cabin', 84),\n",
       " (u'wild', 84),\n",
       " (u'soul', 83),\n",
       " (u'hard', 83),\n",
       " (u'standing', 82),\n",
       " (u'days', 82),\n",
       " (u'harpooneer', 81),\n",
       " (u'mind', 81),\n",
       " (u'ocean', 81),\n",
       " (u'sailor', 81),\n",
       " (u'tail', 80),\n",
       " (u'always', 80),\n",
       " (u'land', 80),\n",
       " (u'young', 80),\n",
       " (u'known', 80),\n",
       " (u'present', 80),\n",
       " (u'large', 79),\n",
       " (u'ere', 79),\n",
       " (u'within', 79),\n",
       " (u'mate', 79),\n",
       " (u'light', 79),\n",
       " (u'length', 78),\n",
       " (u'lay', 78),\n",
       " (u'instant', 77),\n",
       " (u'open', 76),\n",
       " (u'set', 76),\n",
       " (u'fire', 76),\n",
       " (u'beneath', 76)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords excluded from text\n",
    "mostcommon_wo_stopwords = fdist_wo_stopwords.most_common(200)\n",
    "mostcommon_wo_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>0.457972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>0.445569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>0.328182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>0.320491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that</td>\n",
       "      <td>0.213776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>his</td>\n",
       "      <td>0.175317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>0.174763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i</td>\n",
       "      <td>0.147391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>he</td>\n",
       "      <td>0.131384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>but</td>\n",
       "      <td>0.125979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s</td>\n",
       "      <td>0.124870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>as</td>\n",
       "      <td>0.120643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "      <td>0.119534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>with</td>\n",
       "      <td>0.119326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>was</td>\n",
       "      <td>0.113921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>for</td>\n",
       "      <td>0.112050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>all</td>\n",
       "      <td>0.105745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>this</td>\n",
       "      <td>0.096598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>at</td>\n",
       "      <td>0.091400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>whale</td>\n",
       "      <td>0.084956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>by</td>\n",
       "      <td>0.083432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>not</td>\n",
       "      <td>0.079759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>from</td>\n",
       "      <td>0.075393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>him</td>\n",
       "      <td>0.073938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>so</td>\n",
       "      <td>0.073799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>on</td>\n",
       "      <td>0.073592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>be</td>\n",
       "      <td>0.072414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>one</td>\n",
       "      <td>0.063821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>eyes</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>without</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>oh</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>aye</td>\n",
       "      <td>0.010741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>cried</td>\n",
       "      <td>0.010741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>sort</td>\n",
       "      <td>0.010533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>god</td>\n",
       "      <td>0.010533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>know</td>\n",
       "      <td>0.010533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>right</td>\n",
       "      <td>0.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>night</td>\n",
       "      <td>0.010394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>thought</td>\n",
       "      <td>0.010394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>part</td>\n",
       "      <td>0.010325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>once</td>\n",
       "      <td>0.010325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>boats</td>\n",
       "      <td>0.010186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>air</td>\n",
       "      <td>0.009909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>crew</td>\n",
       "      <td>0.009701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>don</td>\n",
       "      <td>0.009632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>take</td>\n",
       "      <td>0.009493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>whole</td>\n",
       "      <td>0.009493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>half</td>\n",
       "      <td>0.009424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>tell</td>\n",
       "      <td>0.009355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>against</td>\n",
       "      <td>0.009286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>thus</td>\n",
       "      <td>0.009216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>things</td>\n",
       "      <td>0.009147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>whaling</td>\n",
       "      <td>0.009078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>thee</td>\n",
       "      <td>0.009078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>came</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>soon</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>hands</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>mast</td>\n",
       "      <td>0.008939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0        the  1.000000\n",
       "1         of  0.457972\n",
       "2        and  0.445569\n",
       "3          a  0.328182\n",
       "4         to  0.320491\n",
       "5         in  0.289100\n",
       "6       that  0.213776\n",
       "7        his  0.175317\n",
       "8         it  0.174763\n",
       "9          i  0.147391\n",
       "10        he  0.131384\n",
       "11       but  0.125979\n",
       "12         s  0.124870\n",
       "13        as  0.120643\n",
       "14        is  0.119534\n",
       "15      with  0.119326\n",
       "16       was  0.113921\n",
       "17       for  0.112050\n",
       "18       all  0.105745\n",
       "19      this  0.096598\n",
       "20        at  0.091400\n",
       "21     whale  0.084956\n",
       "22        by  0.083432\n",
       "23       not  0.079759\n",
       "24      from  0.075393\n",
       "25       him  0.073938\n",
       "26        so  0.073799\n",
       "27        on  0.073592\n",
       "28        be  0.072414\n",
       "29       one  0.063821\n",
       "..       ...       ...\n",
       "170     eyes  0.010810\n",
       "171  without  0.010810\n",
       "172       oh  0.010810\n",
       "173      aye  0.010741\n",
       "174    cried  0.010741\n",
       "175     sort  0.010533\n",
       "176      god  0.010533\n",
       "177     know  0.010533\n",
       "178    right  0.010464\n",
       "179    night  0.010394\n",
       "180  thought  0.010394\n",
       "181     part  0.010325\n",
       "182     once  0.010325\n",
       "183    boats  0.010186\n",
       "184      air  0.009909\n",
       "185     crew  0.009701\n",
       "186      don  0.009632\n",
       "187     take  0.009493\n",
       "188    whole  0.009493\n",
       "189     half  0.009424\n",
       "190     tell  0.009355\n",
       "191  against  0.009286\n",
       "192     thus  0.009216\n",
       "193   things  0.009147\n",
       "194  whaling  0.009078\n",
       "195     thee  0.009078\n",
       "196     came  0.009008\n",
       "197     soon  0.009008\n",
       "198    hands  0.009008\n",
       "199     mast  0.008939\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostcommon_w_stopwords_rfreq = pd.DataFrame(mostcommon_w_stopwords)\n",
    "mostcommon_w_stopwords_rfreq[1] = mostcommon_w_stopwords_rfreq[1]/mostcommon_w_stopwords_rfreq[1][0]\n",
    "mostcommon_w_stopwords_rfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* https://turi.com/products/create/docs/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
